{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.insert(0, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from personflow.loader import PersonalityPostLoader\n",
    "from personflow.preparator import PersonContainer, TrainTestSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored 5624 texts because of too small chunks\n"
     ]
    }
   ],
   "source": [
    "loader = PersonalityPostLoader()\n",
    "persons = loader.run()\n",
    "\n",
    "container = PersonContainer(persons)\n",
    "container.split_posts(10)\n",
    "#container.replace_personality_codes()\n",
    "#container.replace_links()\n",
    "#container.replace_digits()\n",
    "container.evenly_distribute()\n",
    "container.post_joiner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: Counter({'Introvert': 6728, 'Extrovert': 6727})\n",
      "Test size: Counter({'Extrovert': 2884, 'Introvert': 2883})\n"
     ]
    }
   ],
   "source": [
    "ttsplitter = TrainTestSplitter(container)\n",
    "train_x, train_y, test_x, test_y = ttsplitter.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"steve job's was recognized for his striving for efficiency and practicality. his genius is in his systemization of inventions, less so than in invention. this is where claims of se and te come from. pencil. not inf fe. type ~= emotion, type == what drove emotion obvious troll but either way, he'd get there by use of his ni or te. you can get any behavior with any cognition, all cognition describes is the thought process, which may be prone to develop certain behaviors... every edgy ntp and their mother acts on their off days. the very idea of 'borrowing' types and progressively chameleoning screams ne and fe, specifically in that order. it's cause you spend all your time irl ignoring your need for expression, so now you're excitedly exaggerating and projecting your weirdness because you get aroused off the image of you it puts in... just gonna ignore all your rules.  si - normal se - fighting ni - psychic ne - electric ti - steel te - dark fi - grass fe - fairy ixfj  must research si vs ni, i suck at those two. well i think it's being used in a more advisory sense, not moral.  most people like to be in the group, and it's quite healthy considering the type of animals we are. so people tend to correctly... bad quiz, bad link.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=50000, oov_token=\"$oov\")\n",
    "tokenizer.fit_on_texts(train_x)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "train_seq = tokenizer.texts_to_sequences(train_x)\n",
    "train_seq_padded = pad_sequences(\n",
    "    sequences, maxlen=300, padding='post', truncating='post')\n",
    "\n",
    "test_seq = tokenizer.texts_to_sequences(test_x)\n",
    "test_seq_padded = pad_sequences(test_seq, maxlen=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1 29  1 15  1  1 15  1  5  1  1  1 10 12  1  1  7  1  1 27 95 12  1\n",
      " 19 10  1  1  7  1  5  1  1 57  1 23  1  1 90  1 90 34  1  1  1  1 14  1\n",
      " 83  1 54 65 76  1  7  1  1 33  1  8 44 54  1  1 17  1  1 42  1  1 10  3\n",
      "  1  1  1  1 20  1  4  1  1  1  1  1  1  5  1  1  1 25  1  1  1  3 62  1\n",
      "  7  1  1  5  1  1  1  1  5  1  1 12  9  1 41  1  8  1 42 38 61  1  1 38\n",
      "  1 15  1 27 97  1  1  1  5  1 38  1 55  8 54  1  1  3  1  7  8 11  1 12\n",
      " 31  1  1 42 38  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  2  1 43  1  1 67  2 35 41 72  1 12  6 48  1  1 23  1 85 39\n",
      " 24  4 20 12  3  1  5 41  1  1  1  3 90  7  1 51 22 27 39  1  4  1  1  1\n",
      "  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(train_seq_padded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
